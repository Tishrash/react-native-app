{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb56eab9-8de3-4501-adea-33b84f2c08a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "import string\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b345fdf-ba3e-40a4-b4ab-7dca0cc56332",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def remove_punctuations(text):\n",
    "    for punctuation in string.punctuation:\n",
    "        text = text.replace(punctuation, '')\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4733d904-ac19-459c-b561-940508503b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../static/model/model.pickle', 'rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd463f10-bfb1-4018-9e2f-1545da36f77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../static/model/stopwords/english', 'r') as file:\n",
    "    sw = file.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d03151c-74a9-4da9-a563-5765a36cf0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = pd.read_csv('../static/model/vocabulary.txt',header=None)\n",
    "tokens = vocab[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "15230d90-38b7-4b6c-8f1e-92b74468f08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a08704e5-f3b7-46e7-a8d9-0a0e6f855a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(text):\n",
    "    data = pd.DataFrame([text], columns=['feedback'])\n",
    "    data['feedback'] = data['feedback'].apply(lambda x: \" \" .join(x.lower() for x in x.split()))\n",
    "    data['feedback'] = data['feedback'].apply(lambda x: \" \".join(re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', x, flags=re.MULTILINE) for x in x.split()))\n",
    "    data[\"feedback\"] = data[\"feedback\"].apply(remove_punctuations)\n",
    "    data['feedback'] = data[\"feedback\"].str.replace(r'\\d+', '', regex=True)\n",
    "    data[\"feedback\"] = data[\"feedback\"].apply(lambda x: \" \".join(word for word in x.split() if word not in sw))\n",
    "    data['feedback'] = data[\"feedback\"].apply(lambda x:\" \".join(ps.stem(x)for x in x.split()))\n",
    "    data['feedback'] = data[\"feedback\"].apply(lambda x:\" \".join(ps.stem(x)for x in x.split()))\n",
    "    return data[\"feedback\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c764a7ca-d62d-45c6-8626-413c2931e1ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'txt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m preprocessed_data \u001b[38;5;241m=\u001b[39m preprocessing(\u001b[43mtxt\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'txt' is not defined"
     ]
    }
   ],
   "source": [
    "preprocessed_data = preprocessing(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a538b0-3da0-4370-915b-8340bbe237f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cbaed55f-acce-467c-9a51-e131eb565df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def vectorizer(ds, vocabulary):\n",
    "    vectorizer = TfidfVectorizer(vocabulary=vocabulary)\n",
    "    vectorized_lst = vectorizer.fit_transform(ds).toarray()\n",
    "    return vectorized_lst.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e74c42e-6728-40de-a906-a53935cfb40b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17035302-2370-4511-b9cd-a830e774f443",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb610622-3899-499e-b4ee-fddb5ff29ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(vectorized_text):\n",
    "    prediction = model.predict(vectorized_text)  # This returns an array\n",
    "    predicted_label = prediction[0]  # Extract first element if it's a single prediction\n",
    "    labels = {1: \"negative\", 0: \"positive\", -1: \"neutral\"}  # Modify based on your model\n",
    "    return labels.get(predicted_label, \"unknown\")  # Lookup in dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1da4ac0b-4107-4c9d-820b-5694d56a3861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizer saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Assuming 'vectorizer' is your trained vectorizer object\n",
    "with open('../static/model/vectorizer.pkl', 'wb') as file:\n",
    "    pickle.dump(get_prediction, file)\n",
    "\n",
    "print(\"Vectorizer saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ffe3e0fa-72ff-46d8-9afb-256f4609ba5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function get_prediction at 0x1129418a0>\n"
     ]
    }
   ],
   "source": [
    "txt = \"narakai\"  # Define your input text\n",
    "\n",
    "print(get_prediction)  # Print the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec80d83d-7996-4d5a-8fb2-c9cf0d3422c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c38c52-c8f0-4672-932b-fa0743a050fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a67617-1838-4955-82da-743a7c1a1a2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50db0194-1717-4041-8f36-efde9d1e90ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1944374b-2f81-4e8c-ac6b-bd3b5adc70b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e018479a-fc08-4946-9208-42361557aab9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
